{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Comprehensive Guide to Training Oour Packaged Model on Kaggle\n",
    "\n",
    "This notebook provides a detailed, step-by-step workflow for testing and training ou `densenet-pytorch` package in a Kaggle environment. Following this method ensures a clean, reproducible, and professional setup.\n",
    "\n",
    "**The core principle is to treat your code as a versioned dataset, separate from the notebook where you run experiments.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create a Kaggle Dataset from Your GitHub Repository\n",
    "\n",
    "This is the most critical step for a professional workflow. Instead of uploading `.py` files, you will link your GitHub repository directly to Kaggle.\n",
    "\n",
    "1.  **Go to Datasets:** On the Kaggle website, navigate to the \"Datasets\" section and click **\"New Dataset\"**.\n",
    "2.  **Select GitHub:** Choose the option to create a dataset **\"From GitHub\"**.\n",
    "3.  **Enter Repository URL:** Paste the URL of your GitHub repository (e.g., `https://github.com/YourUsername/YourRepo.git`).\n",
    "4.  **Create the Dataset:** Give your dataset a title (e.g., `densenet-pytorch-source`) and click **\"Create\"**. Kaggle will pull the latest version of your code.\n",
    "\n",
    "**Why do this?**\n",
    "-   **Versioning:** Your code is version-controlled. When you push updates to GitHub, you can simply click \"Fetch new version\" on your Kaggle dataset page.\n",
    "-   **Cleanliness:** Your experiment notebooks remain clean and are not cluttered with thousands of lines of model code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Set Up Your Kaggle Notebook Environment\n",
    "\n",
    "Now, create a new Kaggle notebook and configure it correctly.\n",
    "\n",
    "1.  **Add Your Code Dataset:** In your new notebook, click **\"+ Add Data\"** in the right-hand panel. Find the code dataset you just created (e.g., `densenet-pytorch-source`) under the \"Your Datasets\" tab and add it.\n",
    "\n",
    "2.  **Add the Training Data:** Use the same **\"+ Add Data\"** button to add the actual training dataset you need (e.g., the `imagenet-object-localization-challenge` for ImageNet, or search for the CIFAR datasets).\n",
    "\n",
    "3.  **Enable GPU & Internet:** In the right-hand panel under \"Settings\":\n",
    "    -   Set the **Accelerator** to **GPU** (P100 or T4).\n",
    "    -   Turn **Internet** access **On**. This is required for `wandb` and `pip` to work.\n",
    "\n",
    "4.  **Add Your W&B Secret Key:** To log metrics with Weights & Biases:\n",
    "    -   Click the **\"Secrets\"** icon (a key ðŸ”‘) in the left-hand menu.\n",
    "    -   Add a new secret with the exact name `WANDB_API_KEY` and paste your key as the value.\n",
    "    -   **Crucially, ensure the toggle switch next to the secret is turned ON** for this notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Install Your Package Correctly\n",
    "\n",
    "To avoid the `read-only file system` error, you must first copy your code from the read-only `/kaggle/input/` directory to the writable `/kaggle/working/` directory before installing it.\n",
    "\n",
    "**This is the definitive solution to the installation error you encountered.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: COPY THE SOURCE CODE TO A WRITABLE DIRECTORY\n",
    "# Replace 'densenet-pytorch-source' with the actual name of your code dataset.\n",
    "!cp -r /kaggle/input/densenet-pytorch-source/ /kaggle/working/densenet-project\n",
    "\n",
    "# STEP 2: NAVIGATE INTO THE NEW WRITABLE DIRECTORY\n",
    "%cd /kaggle/working/densenet-project\n",
    "\n",
    "# STEP 3: INSTALL THE PACKAGE IN EDITABLE MODE\n",
    "# This command will now succeed because it has permission to write the .egg-info directory here.\n",
    "!pip install -e .\n",
    "\n",
    "# STEP 4: RETURN TO THE MAIN WORKING DIRECTORY TO RUN SCRIPTS\n",
    "%cd /kaggle/working/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Run a Training Session\n",
    "\n",
    "With the package installed, you can now execute your training scripts from the command line, just as you would in a local terminal. You call the script from its location inside your copied project folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Example: Run ImageNet Training ---\n",
    "\n",
    "!python /kaggle/working/densenet-project/scripts/run_imagenet_training.py \\\n",
    "    --input-dir /kaggle/input/imagenet-object-localization-challenge \\\n",
    "    --output-dir /kaggle/working/imagenet_outputs \\\n",
    "    --model-arch densenet121 \\\n",
    "    --epochs 5 \\\n",
    "    --batch-size 128 \\\n",
    "    --num-workers 2 # Kaggle notebooks typically have 2 CPU cores available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Resume an Interrupted Training Session\n",
    "\n",
    "If your training is interrupted (e.g., Kaggle session times out), you can easily resume it thanks to the checkpointing feature.\n",
    "\n",
    "1.  **Find the Run ID:** Go to your Weights & Biases project page. Find the interrupted run and go to its \"Overview\" tab. The Run ID is a short, unique string (e.g., `3a1b2c3d`).\n",
    "\n",
    "2.  **Use the `--resume-id` argument:** Add this argument to your command line instruction. The script will automatically download the last saved checkpoint from W&B and continue from where it left off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Example: Resume an ImageNet Training Session ---\n",
    "# Replace '3a1b2c3d' with the actual ID of your interrupted W&B run.\n",
    "\n",
    "!python /kaggle/working/densenet-project/scripts/run_imagenet_training.py \\\n",
    "    --input-dir /kaggle/input/imagenet-object-localization-challenge \\\n",
    "    --output-dir /kaggle/working/imagenet_outputs \\\n",
    "    --model-arch densenet121 \\\n",
    "    --epochs 15 \\\n",
    "    --batch-size 128 \\\n",
    "    --num-workers 2 \\\n",
    "    --resume-id '3a1b2c3d'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## Conclusion\n",
    "\n",
    "By following this guide, you have a professional, robust, and reproducible workflow for any project on Kaggle. Your code is versioned, your notebooks are clean, and you can easily manage and resume complex training jobs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
